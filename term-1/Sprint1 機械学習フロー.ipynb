{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前回行った各手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_rows\",500)\n",
    "pd.set_option(\"display.max_columns\",500)\n",
    "\n",
    "train = pd.read_csv(\"/Users/nobu/Documents/データセット/home-credit-default-risk/application_train.csv\")\n",
    "test = pd.read_csv(\"/Users/nobu/Documents/データセット/home-credit-default-risk/application_test.csv\")\n",
    "\n",
    "ROC_Score_lst = []#結果を補完するリスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#　objectデータだけ抜き出す\n",
    "train.select_dtypes(include=object).head(100)\n",
    "\n",
    "#ラベルだけ抜き出す\n",
    "object_label = train.select_dtypes(include=object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抜き出したカテゴリ型の特徴量をエンコーディングし元のtrainデータに置き換える\n",
    "import category_encoders as ce\n",
    "encode_data = ce.OrdinalEncoder(cols=list(object_label),handle_unknown='impute')\n",
    "\n",
    "#問１、２用の検証データを作成\n",
    "train_df = encode_data.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dfの中でTARGETとの相関係数が強い（負も含む）上位10項目のインデックスを抽出\n",
    "target_corr_index = train_df.corr()[\"TARGET\"].abs().nlargest(10).index\n",
    "\n",
    "\n",
    "#train_dfの抽出したインデックスで相関係数を算出\n",
    "target_corr_top10 = train_df[target_corr_index].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#欠損値を中央値埋め\n",
    "train_df = train_df.fillna(train_df.median())\n",
    "\n",
    "# 特徴量と目的変数に分け、それぞれをndarrayに変換\n",
    "X = train_df.loc[:,[\"EXT_SOURCE_3\",\"EXT_SOURCE_2\",\"EXT_SOURCE_1\"]]\n",
    "y = train_df[\"TARGET\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7210138261748492\n"
     ]
    }
   ],
   "source": [
    "#訓練用75%と検証用25%に分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=1,stratify=y)\n",
    "\n",
    "#特徴量を標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "std.fit(X_train)\n",
    "\n",
    "std_X_train = std.transform(X_train)\n",
    "std_X_test = std.transform(X_test)\n",
    "\n",
    "#学習\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR =  LogisticRegression()\n",
    "LR.fit(std_X_train, y_train)\n",
    "\n",
    "#推定\n",
    "LR_pred = LR.predict_proba(std_X_test)#predict_probaは各データがそれぞれのクラスに所属する確率を求める\n",
    "\n",
    "#ROCを求めるのに適合させるためにknn１_predの確率の部分を１次元に変換\n",
    "LR_rate = LR_pred[:,1:].flatten()\n",
    "LR_rate\n",
    "\n",
    "#ROCを求める\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, LR_rate))\n",
    "\n",
    "ROC_Score_lst.append(roc_auc_score(y_test, LR_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】クロスバリデーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "logreg = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: \n",
      "[0.91979253 0.91709213 0.91881565 0.91966115 0.92047413]\n"
     ]
    }
   ],
   "source": [
    "# k 分割交差検証（主に回帰に使われる）\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)\n",
    "print('Cross-validation scores: \\n{}'.format(cross_val_score(logreg, X, y, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: \n",
      "[0.91919093 0.91905954 0.91917336 0.91918962 0.91917336]\n"
     ]
    }
   ],
   "source": [
    "# 層化 k 分割交差検証（主にクラス分類に使われる）\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "stratifiedkfold = StratifiedKFold(n_splits=5)\n",
    "print('Cross-validation scores: \\n{}'.format(cross_val_score(logreg, X,y, cv=stratifiedkfold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】グリッドサーチ\n",
    "https://qiita.com/tomov3/items/039d4271ed30490edf7b<br>\n",
    "https://qiita.com/FujiedaTaro/items/5784eda386146f1fd6e7<br>\n",
    "https://qiita.com/saiaron/items/bb96c0f898cd0cbcd788\n",
    "\n",
    "#### GridSearchCVクラスには引数としてモデル、探索範囲、さらにクロスバリデーションを何分割で行うかを与えます。\n",
    "#### クロスバリデーションの機能も含まれているため、これを使用する場合はKFoldクラスを利用する必要はありません。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰のパラメーター詳細\n",
    "https://qiita.com/s_yaginuma/items/460eb7bbd78e9c47df9b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### param_grid=  {\"C\": [0.01, 0.1, 0.5, 1,10,100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.716527903373628\n",
      "Best parameters: {'C': 100}\n",
      "Best cross-validation: 0.7181746492226664\n"
     ]
    }
   ],
   "source": [
    "#param_grid=  {\"C\": [0.01, 0.1, 0.5, 1,10,100]}\n",
    "\n",
    "# GridSearchCVのインスタンスを作成&学習&スコア記録\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# パラメータを dict 型で指定\n",
    "param_grid=  {\"C\": [0.01, 0.1, 0.5, 1,10,100]}\n",
    "\n",
    "# validation set は GridSearchCV が自動で作成してくれるため，training set と test set の分割のみを実行すればよい\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5,scoring='roc_auc')\n",
    "\n",
    "# fit 関数を呼ぶことで交差検証とグリッドサーチがどちらも実行される\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#最良のスコアとパラメータは自動的に best_score_，best_estimator_ 変数にそれぞれ格納されます．\n",
    "\n",
    "print('Test set score: {}'.format(grid_search.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "print('Best cross-validation: {}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ➡︎ ここで重要なのは，パラメータの選択（grid_search.fit(X_train, y_train) の部分）に test set を使用していないという点<br>GridSearchCV により，汎化精度が最も高くなるようなパラメータの発見が可能となります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.7165278778612715\n",
      "Best parameters: {'C': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best cross-validation: 0.7181679138544601\n"
     ]
    }
   ],
   "source": [
    "#param_grid=  {\"C\": [0.01, 0.1, 0.5, 1,10,100],\"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\"penalty\" : [\"l1\",\"l2\"]}\n",
    "\n",
    "\n",
    "# GridSearchCVのインスタンスを作成&学習&スコア記録\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# パラメータを dict 型で指定\n",
    "param_grid=  {\"C\": [0.01, 0.1, 0.5, 1,10,100],\"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\"penalty\" : [\"l1\",\"l2\"]}\n",
    "\n",
    "# validation set は GridSearchCV が自動で作成してくれるため，training set と test set の分割のみを実行すればよい\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=10,scoring='roc_auc')#評価指標roc_aucを指定\n",
    "\n",
    "# fit 関数を呼ぶことで交差検証とグリッドサーチがどちらも実行される\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#最良のスコアとパラメータは自動的に best_score_，best_estimator_ 変数にそれぞれ格納されます．\n",
    "\n",
    "print('Test set score: {}'.format(grid_search.score(X_test, y_test)))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "print('Best cross-validation: {}'.format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】Kaggle Notebooksからの調査"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ①[sklearn.preprocessing.PolynomialFeatures ]\n",
    "sklearn.preprocessing.PolynomialFeatures（degree = 2、interaction_only = False、include_bias = True、order = 'C' ）\n",
    "指定された次数以下の次数を持つ特徴のすべての多項式の組み合わせで構成される新しい特徴行列を生成します。\n",
    "\n",
    "\n",
    "https://www.kaggle.com/willkoehrsen/start-here-a-gentle-introduction で\n",
    "EXT_SOURCE変数とDAYS_BIRTH変数を使用して多項式の特徴を作成するのに用いられている。\n",
    "結果として作成したいくつかの特徴量でTARGETとの相関が高くなっている\n",
    "\n",
    "\n",
    "### ②ドメイン知識をもとに作成された特徴量\n",
    "https://www.kaggle.com/jsaguiar/lightgbm-with-simple-features\n",
    "#### CREDIT_INCOME_PERCENT：クライアントの収入に対するクレジット額の割合<br>train['AMT_CREDIT'] / train['AMT_INCOME_TOTAL']\n",
    "#### ANNUITY_INCOME_PERCENT：クライアントの収入に対するローン年金の割合<br>train['AMT_ANNUITY'] / train['AMT_INCOME_TOTAL']\n",
    "#### CREDIT_TERM：支払いの月数（年金は毎月の支払い期日であるため）<br>train['AMT_ANNUITY'] / train['AMT_CREDIT']\n",
    "#### DAYS_EMPLOYED_PERCENT：クライアントの年齢に対する就業日の割合<br>train['DAYS_EMPLOYED'] / train['DAYS_BIRTH']\n",
    "\n",
    "### ③LightGBMを使っている人が多かった"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】高い汎化性能のモデル作成\n",
    "## オリジナル仮説：EXT_SOURCEを総合的に着目し検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "EXT_SOURCEが信用スコアということでアメリカの信用スコアについて調べた\n",
    "\n",
    "➡︎アメリカの信用情報機関は三つ。(エキファックス（Equifax）エクスペリアン（Experian）トランスユニオン（TransUnion）)\n",
    "<br>集まった金融機関の利用情報と事故情報を元に、「FICOスコア」(300〜850点で個人の信用力を格付けしていく手法)でクレジットスコアが算出される\n",
    "\n",
    "➡︎日本も信用情報機関はCIC、JICC、JBAの三つ。これらはそれぞれ管轄する情報が異なる。\n",
    "<br>例：CICは消費者金融や信販系クレジットカード会社、JICCはネット専業銀行や地方銀行、JBAはメガバンクや、都市銀行や第一・第二地方銀行など\n",
    "\n",
    "➡︎返済力を調べるならこれらを総合的に見るべきでは？\n",
    "\n",
    "\n",
    "➡︎アメリカの評価指標FICOが３００〜８５０点でスコアを算出するなか、今回のデータは全て小数点以下。どう解釈するか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TARGET</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078239</td>\n",
       "      <td>-0.098887</td>\n",
       "      <td>-0.160295</td>\n",
       "      <td>-0.155892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <td>0.078239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.362185</td>\n",
       "      <td>-0.091947</td>\n",
       "      <td>-0.178527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <td>-0.098887</td>\n",
       "      <td>-0.362185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134993</td>\n",
       "      <td>0.109100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <td>-0.160295</td>\n",
       "      <td>-0.091947</td>\n",
       "      <td>0.134993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <td>-0.155892</td>\n",
       "      <td>-0.178527</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.094147</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TARGET  DAYS_BIRTH  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3\n",
       "TARGET        1.000000    0.078239     -0.098887     -0.160295     -0.155892\n",
       "DAYS_BIRTH    0.078239    1.000000     -0.362185     -0.091947     -0.178527\n",
       "EXT_SOURCE_1 -0.098887   -0.362185      1.000000      0.134993      0.109100\n",
       "EXT_SOURCE_2 -0.160295   -0.091947      0.134993      1.000000      0.094147\n",
       "EXT_SOURCE_3 -0.155892   -0.178527      0.109100      0.094147      1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[:,[\"TARGET\",\"DAYS_BIRTH\",\"EXT_SOURCE_1\",\"EXT_SOURCE_2\",\"EXT_SOURCE_3\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TARGETと負の相関があることからEXT_SOURCEの数値が低いほど返済力があると考えられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXT_SOURCEを総合的に見るためにそれぞれを合計する\n",
    "train_df[\"total_EXT_SOURCE\"] = train_df[\"EXT_SOURCE_1\"] + train_df[\"EXT_SOURCE_2\"] + train_df[\"EXT_SOURCE_3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 案１：TARGETとの相関が高かったEXT_SOURCEを合計したものと、DAYS_BIRTHを特徴量に設定しROC得点を算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.loc[:,[\"DAYS_BIRTH\",\"total_EXT_SOURCE\"]].values\n",
    "y = train_df[\"TARGET\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Average scores: \n",
      "0.5830347081056406\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "stratifiedkfold = StratifiedKFold(n_splits=5)\n",
    "print('Cross-validation Average scores: \\n{}'.format(cross_val_score(logreg, X,y, cv=stratifiedkfold,scoring='roc_auc').mean()))\n",
    "\n",
    "\n",
    "ROC_Score_lst.append(0.5830347081056406)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 案２：LightGBMを使う(案１と同条件)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nobu/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Average scores: \n",
      "0.7175745251967905\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb = lgb.LGBMClassifier()\n",
    "\n",
    "stratifiedkfold = StratifiedKFold(n_splits=5)\n",
    "print('Cross-validation Average scores: \\n{}'.format(cross_val_score(lgb, X,y, cv=stratifiedkfold,scoring='roc_auc').mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0)\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'regression',\n",
    "    'metric' : {'l2', 'auc'},\n",
    "    'num_leaves' : 31,\n",
    "    'learning_rate' : 0.05,\n",
    "    'feature_fraction' : 0.9,\n",
    "    'bagging_fraction' : 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose' : 0\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, lgb_train, valid_sets=lgb_test, early_stopping_rounds=100, verbose_eval=100)\n",
    "print(gbm)\n",
    "ROC_Score_lst.append(0.0696189)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 案3：案１で作成した特徴量に加え、以下で作成されていた特徴量を用いてLightGBM\n",
    "https://www.kaggle.com/jsaguiar/lightgbm-with-simple-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#クライアントの収入に対するクレジット額の割合\n",
    "train_df['CREDIT_INCOME_PERCENT'] = train_df['AMT_CREDIT'] / train_df['AMT_INCOME_TOTAL']\n",
    "#クライアントの収入に対するローン支払額の割合\n",
    "train_df['ANNUITY_INCOME_PERCENT'] = train_df['AMT_ANNUITY'] / train_df['AMT_INCOME_TOTAL']\n",
    "#支払いの月数（年金は毎月の支払い期日であるため）\n",
    "train_df['CREDIT_TERM'] = train_df['AMT_ANNUITY'] / train_df['AMT_CREDIT']\n",
    "#クライアントの年齢に対する就業日の割合\n",
    "train_df['DAYS_EMPLOYED_PERCENT'] = train_df['DAYS_EMPLOYED'] / train_df['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.loc[:,[\"total_EXT_SOURCE\",\"CREDIT_INCOME_PERCENT\",\"ANNUITY_INCOME_PERCENT\",\"CREDIT_TERM\",\"DAYS_EMPLOYED_PERCENT\"]]\n",
    "y = train_df[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.743599\tvalid_0's l2: 0.0679309\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[97]\tvalid_0's auc: 0.743649\tvalid_0's l2: 0.0679306\n",
      "<lightgbm.basic.Booster object at 0x1a237a8400>\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'regression',\n",
    "    'metric' : {'l2', 'auc'},\n",
    "    'num_leaves' : 31,\n",
    "    'learning_rate' : 0.05,\n",
    "    'feature_fraction' : 0.9,\n",
    "    'bagging_fraction' : 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose' : 0\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, lgb_train, valid_sets=lgb_test, early_stopping_rounds=100, verbose_eval=100)\n",
    "print(gbm)\n",
    "ROC_Score_lst.append(0.0679306)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 案４：案３から案１で作成したtotal_EXT_SOURCEを抜いて検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.676755\tvalid_0's l2: 0.0704824\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[97]\tvalid_0's auc: 0.676898\tvalid_0's l2: 0.0704786\n",
      "<lightgbm.basic.Booster object at 0x1a22152a90>\n"
     ]
    }
   ],
   "source": [
    "X = train_df.loc[:,[\"CREDIT_INCOME_PERCENT\",\"ANNUITY_INCOME_PERCENT\",\"CREDIT_TERM\",\"DAYS_EMPLOYED_PERCENT\"]]\n",
    "y = train_df[\"TARGET\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'regression',\n",
    "    'metric' : {'l2', 'auc'},\n",
    "    'num_leaves' : 31,\n",
    "    'learning_rate' : 0.05,\n",
    "    'feature_fraction' : 0.9,\n",
    "    'bagging_fraction' : 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose' : 0\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, lgb_train, valid_sets=lgb_test, early_stopping_rounds=100, verbose_eval=100)\n",
    "print(gbm)\n",
    "ROC_Score_lst.append(0.0704786)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_holdout</th>\n",
       "      <td>0.721014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_total_EXT_SOURCE</th>\n",
       "      <td>0.583035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_LightGBM</th>\n",
       "      <td>0.069619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_new_feature</th>\n",
       "      <td>0.067931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_Del_total_EXT_SOURCE</th>\n",
       "      <td>0.070479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ROC_Score\n",
       "1_holdout                0.721014\n",
       "2_total_EXT_SOURCE       0.583035\n",
       "3_LightGBM               0.069619\n",
       "4_new_feature            0.067931\n",
       "5_Del_total_EXT_SOURCE   0.070479"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(ROC_Score_lst,index=[\"1_holdout\",\"2_total_EXT_SOURCE\",\"3_LightGBM\",\n",
    "                                           \"4_new_feature\",\"5_Del_total_EXT_SOURCE\"],columns=[\"ROC_Score\"])\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡︎　①の前回提出したロジスティック回帰＋ホールドアウト法が最も高得点であった。\n",
    "<br>⑤にて④からtotal_EXT_SOURCEを抜いて検証したが、⑤の方が得点が高かったため、EXT_SOURCEを総合的に捉えることは有効ではないと考えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】最終的なモデルの選定\n",
    "### ①は前回提出しているため、⑤で提出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.676755\tvalid_0's l2: 0.0704824\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[97]\tvalid_0's auc: 0.676898\tvalid_0's l2: 0.0704786\n"
     ]
    }
   ],
   "source": [
    "#案３再現\n",
    "\n",
    "#クライアントの収入に対するクレジット額の割合\n",
    "train_df['CREDIT_INCOME_PERCENT'] = train_df['AMT_CREDIT'] / train_df['AMT_INCOME_TOTAL']\n",
    "#クライアントの収入に対するローン支払額の割合\n",
    "train_df['ANNUITY_INCOME_PERCENT'] = train_df['AMT_ANNUITY'] / train_df['AMT_INCOME_TOTAL']\n",
    "#支払いの月数（年金は毎月の支払い期日であるため）\n",
    "train_df['CREDIT_TERM'] = train_df['AMT_ANNUITY'] / train_df['AMT_CREDIT']\n",
    "#クライアントの年齢に対する就業日の割合\n",
    "train_df['DAYS_EMPLOYED_PERCENT'] = train_df['DAYS_EMPLOYED'] / train_df['DAYS_BIRTH']\n",
    "#total_EXT_SOURCE作成\n",
    "train_df[\"total_EXT_SOURCE\"] = train_df[\"EXT_SOURCE_1\"] + train_df[\"EXT_SOURCE_2\"] + train_df[\"EXT_SOURCE_3\"]\n",
    "\n",
    "X = train_df.loc[:,[\"CREDIT_INCOME_PERCENT\",\"ANNUITY_INCOME_PERCENT\",\"CREDIT_TERM\",\"DAYS_EMPLOYED_PERCENT\"]]\n",
    "y = train_df[\"TARGET\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_test = lgb.Dataset(X_test, y_test)\n",
    "\n",
    "params = {\n",
    "    'task' : 'train',\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective' : 'regression',\n",
    "    'metric' : {'l2', 'auc'},\n",
    "    'num_leaves' : 31,\n",
    "    'learning_rate' : 0.05,\n",
    "    'feature_fraction' : 0.9,\n",
    "    'bagging_fraction' : 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose' : 0\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, lgb_train, valid_sets=lgb_test, early_stopping_rounds=100, verbose_eval=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テストデータを訓練データ同様に前処理\n",
    "\n",
    "#欠損値を中央値埋め\n",
    "test.fillna(test.median(),inplace=True)\n",
    "\n",
    "#　objectデータだけ抜き出す\n",
    "test.select_dtypes(include=object)\n",
    "\n",
    "#ラベルだけ抜き出す\n",
    "object_label = test.select_dtypes(include=object).columns\n",
    "\n",
    "#抜き出したカテゴリ型の特徴量をエンコーディングし元のtrainデータに置き換える\n",
    "import category_encoders as ce\n",
    "encode_datae = ce.OrdinalEncoder(cols=list(object_label),handle_unknown='impute')\n",
    "test_df = encode_data.fit_transform(test)\n",
    "\n",
    "#total_EXT_SOURCEを作成\n",
    "test_df[\"total_EXT_SOURCE\"] = test_df[\"EXT_SOURCE_1\"] + test_df[\"EXT_SOURCE_2\"] + test_df[\"EXT_SOURCE_3\"]\n",
    "\n",
    "\n",
    "#クライアントの収入に対するクレジット額の割合\n",
    "test_df['CREDIT_INCOME_PERCENT'] = test['AMT_CREDIT'] / test['AMT_INCOME_TOTAL']\n",
    "#クライアントの収入に対するローン支払額の割合\n",
    "test_df['ANNUITY_INCOME_PERCENT'] = test['AMT_ANNUITY'] / test['AMT_INCOME_TOTAL']\n",
    "#支払いの月数（年金は毎月の支払い期日であるため）\n",
    "test_df['CREDIT_TERM'] = test['AMT_ANNUITY'] / test['AMT_CREDIT']\n",
    "#クライアントの年齢に対する就業日の割合\n",
    "test_df['DAYS_EMPLOYED_PERCENT'] = test['DAYS_EMPLOYED'] / test['DAYS_BIRTH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#推定\n",
    "gbm_pred = gbm.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提出用データ作成\n",
    "submission_data =pd.DataFrame({'SK_ID_CURR': test_df['SK_ID_CURR'], 'TARGET': gbm_pred})\n",
    "submission_data.to_csv('bbbbbbbb', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCORE➡︎0.50562\n",
    "\n",
    "・・・過学習していたのか、、、もう少し試行錯誤してみます、、、"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

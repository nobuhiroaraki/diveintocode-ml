{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1次元の畳み込みニューラルネットワークスクラッチ\n",
    "\n",
    "畳み込みニューラルネットワーク（CNN） のクラスをスクラッチで作成していきます。\n",
    "\n",
    "NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "このSprintでは1次元の 畳み込み層 を作成し、畳み込みの基礎を理解することを目指します。\n",
    "\n",
    "次のSprintでは2次元畳み込み層とプーリング層を作成することで、一般的に画像に対して利用されるCNNを完成させます。\n",
    "\n",
    "クラスの名前はScratch1dCNNClassifierとしてください。\n",
    "\n",
    "クラスの構造などは前のSprintで作成したScratchDeepNeuralNetrout_wkClassifierを参考にしてください。\n",
    "\n",
    "# 1次元畳み込み層とは\n",
    "CNNでは画像に対しての2次元畳み込み層が定番ですが、ここでは理解しやすくするためにまずは1次元畳み込み層を実装します。1次元畳み込みは実用上は自然言語や波形データなどの 系列データ で使われることが多いです。\n",
    "\n",
    "\n",
    "畳み込みは任意の次元に対して考えることができ、立体データに対しての3次元畳み込みまではフレームワークで一般的に用意されています。\n",
    "\n",
    "\n",
    "# データセットの用意\n",
    "検証には引き続きMNISTデータセットを使用します。1次元畳み込みでは全結合のニューラルネットワークと同様に平滑化されたものを入力します。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(palette=\"bright\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造は前のSprintで作成した全結合層のFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。\n",
    "\n",
    "\n",
    "ここでは パディング は考えず、ストライド も1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。\n",
    "\n",
    "\n",
    "\n",
    "### フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "\n",
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b\n",
    "$$\n",
    "\n",
    "\n",
    "$a_i$ : 出力される配列のi番目の値\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$x_{(i+s)}$ : 入力の配列の(i+s)番目の値\n",
    "\n",
    "\n",
    "$w_s$ : 重みの配列のs番目の値\n",
    "\n",
    "\n",
    "$b$ : バイアス項\n",
    "\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "\n",
    "\n",
    "### 次に更新式です。ここがAdaGradなどに置き換えられる点は全結合層と同様です。\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "w_s^{\\prime} = w_s - \\alpha \\frac{\\partial L}{\\partial w_s} \\\\\n",
    "b^{\\prime} = b - \\alpha \\frac{\\partial L}{\\partial b}\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_s}$ : $w_s$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b}$ : $b$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "\n",
    "### 勾配 $\\frac{\\partial L}{\\partial w_s}$ や $\\frac{\\partial L}{\\partial b}$ を求めるためのバックプロパゲーションの数式が以下です。\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_s} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}x_{(i+s)}\\\\\n",
    "\\frac{\\partial L}{\\partial b} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi番目の値\n",
    "\n",
    "\n",
    "$N_{out}$ : 出力のサイズ\n",
    "\n",
    "\n",
    "\n",
    "### 前の層に流す誤差の数式は以下です。\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x_j} = \\sum_{s=0}^{F-1} \\frac{\\partial L}{\\partial a_{(j-s)}}w_s\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_j}$ : 前の層に流す誤差の配列のj番目の値\n",
    "\n",
    "\n",
    "ただし、 $j-s<0$ または $j-s>N_{out}-1$ のとき $\\frac{\\partial L}{\\partial a_{(j-s)}} =0$ です。\n",
    "\n",
    "\n",
    "全結合層との大きな違いは、重みが複数の特徴量に対して共有されていることです。\n",
    "\n",
    "この場合は共有されている分の誤差を全て足すことで勾配を求めます。\n",
    "\n",
    "計算グラフ上での分岐はバックプロパゲーションの際に誤差の足し算をすれば良いことになります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    1次元畳み込み層\n",
    "    \"\"\"\n",
    "    def __init__(self,b,w,in_size,pad,stride_size):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.in_size = in_size\n",
    "        self.pad = pad\n",
    "        self.stride_size = stride_size\n",
    "        \n",
    "        self.filter_size = len(self.w)\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        w : 重みの初期値\n",
    "        b : バイアスの初期値\n",
    "        in_size : 入力データの数\n",
    "        pad : パディングする数\n",
    "        stride_size : ストライド の大きさ\n",
    "        filter_size : フィルターの大きさ（1次元なので重みの数）\n",
    "        \"\"\"\n",
    "        \n",
    "    #1次元畳み込み後の出力サイズの計算(問２)\n",
    "    def cul_out_size(self):\n",
    "        out_size = (self.in_size+2*self.pad - self.filter_size)/self.stride_size + 1\n",
    "\n",
    "        return int(out_size)#floatをintに変換して出力\n",
    "\n",
    "\n",
    "    #順伝播\n",
    "    def forward(self,X):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 入力(in_size, )\n",
    "        A : 出力(out_size, )\n",
    "        \"\"\"\n",
    "        #出力サイズを計算\n",
    "        out_size = self.cul_out_size()\n",
    "        \n",
    "        #出力サイズの数分の配列を作成\n",
    "        A = np.ones(out_size)\n",
    "        \n",
    "        #出力サイズの数だけフィルターに通す\n",
    "        for i in range (out_size):\n",
    "            A[i] = np.sum(X[i:i+self.filter_size]*self.w)+self.b#1次元の配列をストライド １でfilter_sizeの幅でズラして、\n",
    "        return A#重みとかけ足し合わせたものにバイアスをたす\n",
    "    \n",
    "    \n",
    "        #逆伝播\n",
    "    def backward(self,X,dA):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 入力(in_size, )\n",
    "        dA : 出力の勾配(out_size, )\n",
    "        \"\"\"\n",
    "        #出力の大きさ\n",
    "        out_size = self.cul_out_size()\n",
    "        \n",
    "        #バイアスの勾配\n",
    "        dB = np.sum(dA)\n",
    "        \n",
    "        #重みの勾配\n",
    "        #フィルターの大きさ（重みの数）だけ配列を作成\n",
    "        dW = np.zeros(self.filter_size)\n",
    "        for i in range(self.filter_size):\n",
    "            #入力データをfilter_size分ズラしながら出力の勾配とかけていき、作成した配列を更新していく\n",
    "            dW[i] = X[i:i+out_size].T@dA\n",
    "        \n",
    "        #入力の勾配   \n",
    "        #(出力サイズ、入力サイズの配列を作成)\n",
    "        new_W = np.zeros((out_size,self.in_size))\n",
    "        #フィルターサイズずつ移動してフィルターを適用していく\n",
    "        for i in range(out_size):\n",
    "            new_W[i,i:i+self.filter_size] = self.w\n",
    "        #フィルターをかけ終えたものと出力の勾配をかける\n",
    "        dX = dA@new_W\n",
    "        \n",
    "        return dB,dW,dX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。\n",
    "\n",
    "パディングやストライドも含めています。この計算を行う関数を作成してください。\n",
    "\n",
    "$$\n",
    "N_{out} =  \\frac{N_{in}+2P-F}{S} + 1\\\\\n",
    "$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$S$ : ストライドのサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1次元畳み込み後の出力サイズの計算(問２)\n",
    "def cul_out_size(self):\n",
    "    out_size = (self.in_size+2*self.pad - self.filter_size)/self.stride_size + 1\n",
    "\n",
    "    return int(out_size)#floatをintに変換して出力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】小さな配列での1次元畳み込み層の実験\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。\n",
    "\n",
    "\n",
    "入力x、重みw、バイアスbを次のようにします。\n",
    "\n",
    "```python\n",
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "```\n",
    "フォワードプロパゲーションをすると出力は次のようになります。\n",
    "\n",
    "```python\n",
    "a = np.array([35, 50])\n",
    "```\n",
    "\n",
    "次にバックプロパゲーションを考えます。誤差は次のようであったとします。\n",
    "```python\n",
    "delta_a = np.array([10, 20])\n",
    "```\n",
    "\n",
    "バックプロパゲーションをすると次のような値になります。\n",
    "```python\n",
    "delta_b = np.array([30])\n",
    "delta_w = np.array([50, 80, 110])\n",
    "delta_x = np.array([30, 110, 170, 140])\n",
    "```\n",
    "\n",
    "実装上の工夫\n",
    "畳み込みを実装する場合は、まずはfor文を重ねていく形で構いません。\n",
    "\n",
    "しかし、できるだけ計算は効率化させたいため、以下の式を一度に計算する方法を考えることにします。\n",
    "\n",
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b\n",
    "$$\n",
    "\n",
    "バイアス項は単純な足し算のため、重みの部分を見ます。\n",
    "\n",
    "$$\n",
    "\\sum_{s=0}^{F-1}x_{(i+s)}w_s\n",
    "$$\n",
    "\n",
    "これは、xの一部を取り出した配列とwの配列の内積です。具体的な状況を考えると、以下のようなコードで計算できます。\n",
    "\n",
    "この例では流れを分かりやすくするために、各要素同士でアダマール積を計算してから合計を計算しています。これは結果的に内積と同様です。\n",
    "\n",
    "```python\n",
    "x = np.array([1, 2, 3, 4])\n",
    "w = np.array([3, 5, 7])\n",
    "a = np.empty((2, 3))\n",
    "indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
    "indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
    "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
    "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
    "a = a.sum(axis=1)\n",
    "```\n",
    "\n",
    "ndarrayは配列を使ったインデックス指定ができることを利用した方法です。\n",
    "\n",
    "また、二次元配列を使えば一次元配列から二次元配列が取り出せます。\n",
    "\n",
    "```python\n",
    "x = np.array([1, 2, 3, 4])\n",
    "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n",
    "print(x[indexes]) # ([[1, 2, 3], [2, 3, 4]])\n",
    "```\n",
    "\n",
    "このこととブロードキャストなどをうまく組み合わせることで、一度にまとめて計算することも可能です。\n",
    "\n",
    "\n",
    "畳み込みの計算方法に正解はないので、自分なりに効率化していってください。\n",
    "\n",
    "\n",
    "《参考》\n",
    "\n",
    "\n",
    "以下のページのInteger array indexingの部分がこの方法についての記述です。\n",
    "\n",
    "\n",
    "Indexing — NumPy v1.17 Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 2, 3, 4])\n",
    "W = np.array([3, 5, 7])\n",
    "B = np.array([1])\n",
    "dA = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward:[35. 50.]\n",
      "delta_B:30\n",
      "delta_W:[ 50.  80. 110.]\n",
      "delta_X:[ 30. 110. 170. 140.]\n"
     ]
    }
   ],
   "source": [
    "SC1 =  SimpleConv1d(b=B,w=W,in_size=len(X),pad=0,stride_size=1)\n",
    "\n",
    "print(\"forward:{}\".format(SC1.forward(X)))\n",
    "\n",
    "dB,dW,dX = SC1.backward(X,dA)\n",
    "print(\"delta_B:{}\".format(dB))\n",
    "print(\"delta_W:{}\".format(dW))\n",
    "print(\"delta_X:{}\".format(dX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。\n",
    "\n",
    "\n",
    "例えば以下のようなx, w, bがあった場合は、\n",
    "\n",
    "```python\n",
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）\n",
    "```\n",
    "出力は次のようになります。\n",
    "\n",
    "```python\n",
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。\n",
    "```\n",
    "\n",
    "入力が2チャンネル、出力が3チャンネルの例です。計算グラフを書いた上で、バックプロパゲーションも手計算で考えてみましょう。計算グラフの中には和と積しか登場しないので、微分を新たに考える必要はありません。\n",
    "\n",
    "\n",
    "《補足》\n",
    "\n",
    "\n",
    "チャンネル数を加える場合、配列をどういう順番にするかという問題があります。(バッチサイズ、チャンネル数、特徴量数)または(バッチサイズ、特徴量数、チャンネル数)が一般的で、ライブラリによって順番は異なっています。（切り替えて使用できるものもあります）\n",
    "\n",
    "\n",
    "今回のスクラッチでは自身の実装上どちらが効率的かを考えて選んでください。上記の例ではバッチサイズは考えておらず、(チャンネル数、特徴量数)です。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】（アドバンス課題）ミニバッチへの対応\n",
    "ここまでの課題はバッチサイズ1で良いとしてきました。しかし、実際は全結合層同様にミニバッチ学習が行われます。\n",
    "\n",
    "Conv1dクラスを複数のデータが同時に計算できるように変更してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】学習と推定\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えてMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "出力層だけは全結合層をそのまま使ってください。ただし、チャンネルが複数ある状態では全結合層への入力は行えません。\n",
    "\n",
    "その段階でのチャンネルは1になるようにするか、 平滑化 を行なってください。\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : (データ数, チャンネル, 高さ, 幅)の4次元配列からなる入力データ\n",
    "    filter_h : フィルターの高さ\n",
    "    filter_w : フィルターの幅\n",
    "    stride : ストライド\n",
    "    pad : パディング\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    col : 2次元配列\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col :\n",
    "    input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n",
    "    filter_h :\n",
    "    filter_w\n",
    "    stride\n",
    "    pad\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    1次元畳み込み層クラス（padding=0,stride=1）\n",
    "    \"\"\"\n",
    "    def __init__(self, W, b, stride=1, pad=0,lr=0.01 ):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.lr = lr\n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        -----------------------\n",
    "        x (numpy.ndarray): 入力 shape(N, C, H, W)\n",
    "        \n",
    "        out(numpy.ndarray):出力shape(N, FN, out_h, out_w)\n",
    "        \"\"\"\n",
    "        #フィルター数、チャネル数、フィルターの高さ、フィルターの幅を重みのshapeをもとに作成\n",
    "        FN, C, FH, FW = self.W.shape#FN:フィルター数、C:チャンネル数、FH:フィルターの高さ、FW:幅\n",
    "        \n",
    "        #入力、チャネル数（チャネル数はフィルターと入力同じ数）、入力の高さ、入力の幅を入力データをもとに作成\n",
    "        N, C, H, W = x.shape#N:バッチサイズ、x_C:チャンネル数、H：入力データの高さ、W:幅\n",
    "        \n",
    "        #出力される特徴マップの高さ・幅を算出\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        #画像からユニットを取り出して列として並べる\n",
    "        # (N, C, H, W) → (N * out_h * out_w, C * FH * FW)\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        \n",
    "        #フィルターにも同様の処理を\n",
    "        # (FN, C, FH, FW) → (C * FH * FW, FN)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "        \n",
    "        #入力と重みをかけてバイアスを足す\n",
    "        #(N * out_h * out_w, C * FH * FW)・(C * FH * FW, FN) → (N * out_h * out_w, FN)\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        #計算しやすいように入れ替える\n",
    "        # (N * out_h * out_w, FN) → (N, out_h, out_w, FN) → (N, FN, out_h, out_w)\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        #逆伝播の時に使うため保持する\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \"\"\"\n",
    "        #フィルター数、チャネル数、フィルターの高さ、フィルターの幅を重みのshapeをもとに作成\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        #計算しやすいように入れ替える\n",
    "        # (N, FN, out_h, out_w) → (N, out_h, out_w, FN) → (N * out_h * out_w, FN)\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "        \n",
    "        #出力の勾配を列方向に足し合わせる\n",
    "        self.db = np.sum(dout, axis=0)# → (FN)\n",
    "        \n",
    "        #順伝播時にim2col変換したものと出力の勾配の行列積を算出する\n",
    "        self.dW = np.dot(self.col.T, dout)# → (C * FH * FW, FN)\n",
    "        \n",
    "        #計算しやすいように入れ替える\n",
    "        # (C * FH * FW, FN) → (FN, C * FH * FW) → (FN, C, FH, FW)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "        \n",
    "        #出力の勾配とim2col変換をしたフィルターの行列積を求める\n",
    "        dcol = np.dot(dout, self.col_W.T)# → (N * out_h * out_w, C * FH * FW)\n",
    "        \n",
    "        #画像形式に戻す（col2im変換）\n",
    "        # (N * out_h * out_w, C * FH * FW) → (N, C, H, W)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "        \n",
    "        # 逆伝播して求めた勾配でパラメータを更新\n",
    "        self.update()\n",
    "        return dx\n",
    "    \n",
    "    def update(self):\n",
    "        self.W -= self.lr * self.dW\n",
    "        self.b -= self.lr * self.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================ミニバッチ===================================================\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "    \n",
    "    \n",
    "#===========================================平滑化===================================================\n",
    "class Flatten:\n",
    "    \"\"\"\n",
    "    平滑化\n",
    "    -----------------------\n",
    "    forward時はチャンネル、高さ、幅の3次元を1次元に\n",
    "    backward時は元の入力の形状に\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        #入力サイズ、チャネル数、入力の高さ、幅を入力の形状に\n",
    "        N, C, H, W = x.shape\n",
    "        #平滑化\n",
    "        flatten = x.reshape(N, -1)\n",
    "        #逆伝播で入力と同じ形状にするため入力を保持\n",
    "        self.x = x\n",
    "        \n",
    "        return flatten\n",
    "    \n",
    "    def backward(self, d_flatten):\n",
    "        #入力と同じ形状に変換\n",
    "        dx = d_flatten.reshape(self.x.shape)\n",
    "        \n",
    "        return dx\n",
    "#===========================================全結合層===================================================\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        \n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        \n",
    "        #初期化手法\n",
    "        self.initializer = initializer\n",
    "        \n",
    "        #最適化手法\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # 指定したinitializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = self.initializer.W(self.n_nodes1,self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        #フォワード時の入力Xをインスタンス変数として保持\n",
    "        self.X = X\n",
    "        \n",
    "        #順伝播\n",
    "        self.A = self.X@self.W + self.B\n",
    "        \n",
    "        return self.A\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 逆伝播\n",
    "        self.dB = np.sum(dA,axis=0)#dA・・・逆伝播する際に活性化関数に通して出力された値\n",
    "        self.dW = self.X.T@dA\n",
    "        self.dZ = dA@self.W.T\n",
    "        \n",
    "        #インスタンスの重みとバイアス自身を指定した最適手法により求めた値で更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return self.dZ\n",
    "    \n",
    "    \n",
    "#===========================================初期化手法===================================================\n",
    "#ガウス分布によるシンプルな初期化手法\n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :　重みの初期値\n",
    "        \"\"\"\n",
    "        W = self.sigma*np.random.randn(n_nodes1,n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :バイアスの初期値\n",
    "        \"\"\"\n",
    "        B = self.sigma*np.random.randn(1,n_nodes2)\n",
    "        return B\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#===========================================最適化手法===================================================\n",
    "#（問３）\n",
    "#最適化手法（SGD）\n",
    "class SGD():\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "       \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        #パラメータを誤差逆伝播で算出したものに学習率をかけて更新\n",
    "        layer.W -= self.lr*layer.dW/20#バッチサイズで割る\n",
    "        layer.B -= self.lr*layer.dB/20\n",
    "        \n",
    "        #パラメータを更新したインスタンスを返す\n",
    "        return layer\n",
    "  \n",
    " #===========================================活性化関数===================================================  \n",
    "#ハイパボリックタンジェント関数を活性化関数として使用\n",
    "class Tanh:\n",
    "    '''\n",
    "    ハイパボリックタンジェント関数\n",
    "    '''\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ * (1 - np.tanh(self.A)**2)\n",
    "        return dA\n",
    "\n",
    "        \n",
    "#ソフトマックス関数を活性化関数として使用\n",
    "class Softmax:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 各層に入力される値(batch_size, n_nodes_1)\n",
    "        dZ : バックワード時に前に流す勾配(batch_size, n_nodes1)\n",
    "\n",
    "       Returns\n",
    "        -------\n",
    "        Z : 各層からの出力される値(batch_size, n_nodes1)\n",
    "        dA : バックワード時に後ろから流れてきた勾配(batch_size, n_nodes2)\n",
    "        \"\"\"\n",
    "        def forward(self,A):\n",
    "            Z = np.exp(A)/np.sum(np.exp(A),axis=1).reshape(-1,1)\n",
    "            \n",
    "            return Z\n",
    "         \n",
    "        def backward(self,A,y):\n",
    "            dA = self.forward(A) - y\n",
    "            #back時は交差エントロピー誤差も計算\n",
    "            L = - np.sum(y * np.log(self.forward(A))) / len(y)\n",
    "            \n",
    "            return dA,L        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d_NN():\n",
    "    \"\"\"\n",
    "    １次元の畳み込み層を加えたニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, epoch=10,batch_size=20,sigma=0.1,lr=0.01,verbose=False):\n",
    "        \n",
    "        #パラメータ\n",
    "        self.epoch = epoch \n",
    "        self.batch_size =  batch_size\n",
    "        self.sigma = sigma \n",
    "        self.lr = lr \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        #全結合層で使用\n",
    "        self.optimizer = SGD\n",
    "        self.initializer = SimpleInitializer\n",
    "        self.activater = Tanh()\n",
    "        self.softmax = Softmax()\n",
    "        self.flat = Flatten()\n",
    "        \n",
    "        #畳み込み層で使用\n",
    "        self.FN = 30#フィルターの数\n",
    "        self.C = 1#チャネル数\n",
    "        self.FH = 1#フィルターの縦の大きさ\n",
    "        self.FW = 5#フィルターの幅\n",
    "        self.pad = 0#padding\n",
    "        self.stride = 1#ストライド \n",
    "        self.n_output = 10 #出力数\n",
    "       \n",
    "        # 畳み込み層クラス呼び出しのために、重みとバイアスの初期値を生成\n",
    "        self.w = self.sigma * np.random.randn(self.FN, self.C, self.FH, self.FW)\n",
    "        self.b = self.sigma * np.random.randn(self.FN,)\n",
    "        #畳み込みクラスを呼び出し\n",
    "        self.conv = Conv1d(self.w,self.b)\n",
    "\n",
    "        # 全結合層クラスを呼び出すために、全結合層への入力を計算する\n",
    "        out_h, out_w = self.out_size(1, 784, self.pad, self.FH, self.FW, self.stride)\n",
    "        node_n = self.FN * out_h * out_w\n",
    "        #全結合層クラスを呼び出し\n",
    "        self.FC = FC(node_n, self.n_output, self.initializer(self.sigma), self.optimizer(self.lr))\n",
    "        \n",
    "        #グラフ描画用にlossを保存するリスト\n",
    "        self.loss_train = []\n",
    "        self.loss_val = []\n",
    "\n",
    "    #畳み込み層からの出力サイズを計算    \n",
    "    def out_size(self, H, W, P, FH, FW, S):\n",
    "        out_h = (H + 2 * P - FH) // S + 1\n",
    "        out_w = (W + 2 * P - FW) // S + 1\n",
    "        return out_h, out_w\n",
    "        \n",
    "\n",
    "    #学習\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"  \n",
    "        #バッチごとに計算\n",
    "        for epoch in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=epoch)\n",
    "            #エポックごとにlossを初期化\n",
    "            loss = 0\n",
    "            val_loss = 0\n",
    "            #エポックごとにイテレーション数を初期化\n",
    "            iter_num = 0\n",
    "            \n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "                # フォワード\n",
    "                A1 = self.conv.forward(mini_X)\n",
    "                Z1 = self.activater.forward(A1)\n",
    "                F1 = self.flat.forward(Z1)\n",
    "                A2 = self.FC.forward(F1)\n",
    "                Z2 = self.softmax.forward(A2)\n",
    "\n",
    "                # バックワード\n",
    "                dA2, loss = self.softmax.backward(Z2, mini_y)\n",
    "                dZ2 = self.FC.backward(dA2)\n",
    "                dF1 = self.flat.backward(dZ2)\n",
    "                dA1 = self.activater.backward(dF1)\n",
    "                dZ1 = self.conv.backward(dA1)\n",
    "            \n",
    "                # 求めたパラメータで再度通る\n",
    "                A1 = self.conv.forward(X)\n",
    "                Z1 = self.activater.forward(A1)\n",
    "                F1 = self.flat.forward(Z1)\n",
    "                A2 = self.FC.forward(F1)\n",
    "                Z2 = self.softmax.forward(A2)  \n",
    "                 # iイテレーションごとに交差エントロピーを計算\n",
    "                loss += self.softmax.backward(Z2, y)[1]\n",
    "                \n",
    "                #エポックの平均を出すためにイテレーション数を記録\n",
    "                iter_num+=1\n",
    "                \n",
    "                #valデータが入力されたら順伝播＆softmax.backwardで交差エントロピー誤差を算出\n",
    "                if X_val is not None:\n",
    "                    A1 = self.conv.forward(X_val)\n",
    "                    Z1 = self.activater.forward(A1)\n",
    "                    F1 = self.flat.forward(Z1)\n",
    "                    A2 = self.FC.forward(F1)\n",
    "                    Z2 = self.softmax.forward(A2)         \n",
    "                    val_loss += self.softmax.backward(Z2, y_val)[1]\n",
    "                    \n",
    "            #エポックごとのlossの平均を算出、リストに格納\n",
    "            ave_loss = loss/iter_num\n",
    "            ave_val_loss = val_loss/iter_num\n",
    "            self.loss_train.append(ave_loss)\n",
    "            self.loss_val.append(ave_val_loss)\n",
    "            \n",
    "            if self.verbose:\n",
    "                #verboseをTrueにした際は各エポックごとの損失の平均を出力する\n",
    "                print(\"Epoch{}\".format(epoch))\n",
    "                print(\"loss:{:.10f}/val_loss:{:.10f}\".format(ave_loss,ave_val_loss))\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        #学習したパラメータで畳み込み層から全部通る\n",
    "        A1 = self.conv.forward(X)\n",
    "        Z1 = self.activater.forward(A1)\n",
    "        F1 = self.flat.forward(Z1)\n",
    "        A2 = self.FC.forward(F1)\n",
    "        Z2 = self.softmax.forward(A2)\n",
    "        #sofmaxを通した最後の層で確率が一番高いものを推定結果とする\n",
    "        return np.argmax(Z2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット読み込み\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# # 標準化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# # チャネル数の軸を追加\n",
    "X_train = X_train[:, np.newaxis, np.newaxis, :]\n",
    "X_test = X_test[:, np.newaxis, np.newaxis, :]\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# ワンホットエンコーディング\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_val[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0\n",
      "loss:0.9258164434/val_loss:2.3538840484\n",
      "Epoch1\n",
      "loss:0.8452629657/val_loss:2.3047531766\n",
      "Epoch2\n",
      "loss:0.8285884401/val_loss:2.2423162311\n",
      "Epoch3\n",
      "loss:0.7949456351/val_loss:2.0875347032\n",
      "Epoch4\n",
      "loss:0.7032079653/val_loss:2.0785743313\n",
      "Epoch5\n",
      "loss:0.7169266746/val_loss:2.0846486153\n",
      "Epoch6\n",
      "loss:0.7459038356/val_loss:2.0516895855\n",
      "Epoch7\n",
      "loss:0.7146775341/val_loss:2.0333288060\n",
      "Epoch8\n",
      "loss:0.7496720624/val_loss:2.0616240351\n",
      "Epoch9\n",
      "loss:0.7607874921/val_loss:2.0393869351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44658333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C1NN =  Conv1d_NN(\n",
    "    epoch=10,\n",
    "    batch_size=20,\n",
    "    sigma=0.1,\n",
    "    lr=0.03,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "C1NN.fit(X_train[:100], y_train_one_hot[:100], X_val[:50], y_test_one_hot[:50])\n",
    "pred = C1NN.predict(X_val)\n",
    "accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x13c6d4cc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(C1NN.loss_train, label='train')\n",
    "plt.plot(C1NN.loss_val, label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

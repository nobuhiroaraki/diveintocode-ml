{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2次元の畳み込みニューラルネットワークスクラッチ\n",
    "\n",
    "2次元に対応した畳み込みニューラルネットワーク（CNN）のクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "プーリング層なども作成することで、CNNの基本形を完成させます。クラスの名前はScratch2dCNNClassifierとしてください。\n",
    "\n",
    "# データセットの用意\n",
    "引き続きMNISTデータセットを使用します。2次元畳み込み層へは、28×28の状態で入力します。\n",
    "\n",
    "\n",
    "今回は白黒画像ですからチャンネルは1つしかありませんが、チャンネル方向の軸は用意しておく必要があります。\n",
    "\n",
    "\n",
    "(n_samples, n_channels, height, width)のNCHWまたは(n_samples, height, width, n_channels)のNHWCどちらかの形にしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(palette=\"bright\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像データから配列に変換する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : (データ数, チャンネル, 高さ, 幅)の4次元配列からなる入力データ\n",
    "    filter_h : フィルターの高さ\n",
    "    filter_w : フィルターの幅\n",
    "    stride : ストライド\n",
    "    pad : パディング\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    col : 2次元配列\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配列から画像データに変換する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col :\n",
    "    input_shape : 入力データの形状（例：(10, 1, 28, 28)）\n",
    "    filter_h :\n",
    "    filter_w\n",
    "    stride\n",
    "    pad\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】2次元畳み込み層の作成\n",
    "1次元畳み込み層のクラスConv1dを発展させ、2次元畳み込み層のクラスConv2dを作成してください。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "## $$\n",
    "a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、mチャンネルの値\n",
    "\n",
    "\n",
    "$i$ : 配列の行方向のインデックス\n",
    "\n",
    "\n",
    "$j$ : 配列の列方向のインデックス\n",
    "\n",
    "\n",
    "$m$ : 出力チャンネルのインデックス\n",
    "\n",
    "\n",
    "$K$ : 入力チャンネル数\n",
    "\n",
    "\n",
    "$F_{h}, F_{w}$ : 高さ方向（h）と幅方向（w）のフィルタのサイズ\n",
    "\n",
    "\n",
    "$x_{(i+s),(j+t),k}$ : 入力の配列の(i+s)行(j+t)列、kチャンネルの値\n",
    "\n",
    "\n",
    "$w_{s,t,k,m}$ : 重みの配列のs行t列目。kチャンネルの入力に対して、mチャンネルへ出力する重み\n",
    "\n",
    "\n",
    "$b_m$ : mチャンネルへの出力のバイアス項\n",
    "\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "\n",
    "次に更新式です。1次元畳み込み層や全結合層と同じ形です。\n",
    "\n",
    "\n",
    "## $$\n",
    "w_{s,t,k,m}^{\\prime} = w_{s,t,k,m} - \\alpool_ha \\frac{\\partial L}{\\partial w_{s,t,k,m}} \\\\\n",
    "b_{m}^{\\prime} = b_{m} - \\alpool_ha \\frac{\\partial L}{\\partial b_{m}}\n",
    "$$\n",
    "\n",
    "$\\alpool_ha$ : 学習率\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_{s,t,k,m}}$ : $w_{s,t,k,m}$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b_{m}}$ : $b_{m}$ に関する損失 $L$ の勾配\n",
    "\n",
    "\n",
    "勾配 $\\frac{\\partial L}{\\partial w_{s,t,k,m}}$ や $\\frac{\\partial L}{\\partial b_{m}}$ を求めるためのバックプロパゲーションの数式が以下である。\n",
    "\n",
    "\n",
    "## $$\n",
    "\\frac{\\partial L}{\\partial w_{s,t,k,m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1} \\frac{\\partial L}{\\partial a_{i,j,m}}x_{(i+s)(j+t),k}\\\\\n",
    "\\frac{\\partial L}{\\partial b_{m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1}\\frac{\\partial L}{\\partial a_{i,j,m}}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi行j列、mチャンネルの値\n",
    "\n",
    "\n",
    "$N_{out,h},N_{out,w}$ : 高さ方向（h）と幅方向（w）の出力のサイズ\n",
    "\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "## $$ \n",
    "\\frac{\\partial L}{\\partial x_{i,j,k}} = \\sum_{m=0}^{M-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1} \\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}}w_{s,t,k,m}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_{i,j,k}}$ : 前の層に流す誤差の配列のi列j行、kチャンネルの値\n",
    "\n",
    "\n",
    "$M$ : 出力チャンネル数\n",
    "\n",
    "\n",
    "ただし、 $i-s<0$ または $i-s>N_{out,h}-1$ または $j-t<0$ または $j-t>N_{out,w}-1$ のとき $\\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}} =0$ です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    \"\"\"\n",
    "    1次元畳み込み層クラス（padding=0,stride=1）\n",
    "    \"\"\"\n",
    "    def __init__(self, W, b, stride=1, pad=0,lr=0.01 ):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.lr = lr\n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        -----------------------\n",
    "        x (numpy.ndarray): 入力 shape(N, C, H, W)\n",
    "        \n",
    "        out(numpy.ndarray):出力shape(N, FN, out_h, out_w)\n",
    "        \"\"\"\n",
    "        #フィルター数、チャネル数、フィルターの高さ、フィルターの幅を重みのshapeをもとに作成\n",
    "        FN, C, FH, FW = self.W.shape#FN:フィルター数、C:チャンネル数、FH:フィルターの高さ、FW:幅\n",
    "        \n",
    "        #入力、チャネル数（チャネル数はフィルターと入力同じ数）、入力の高さ、入力の幅を入力データをもとに作成\n",
    "        N, C, H, W = x.shape#N:バッチサイズ、x_C:チャンネル数、H：入力データの高さ、W:幅\n",
    "        \n",
    "        #出力される特徴マップの高さ・幅を算出\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        #画像からユニットを取り出して列として並べる\n",
    "        # (N, C, H, W) → (N * out_h * out_w, C * FH * FW)\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        \n",
    "        #フィルターにも同様の処理を\n",
    "        # (FN, C, FH, FW) → (C * FH * FW, FN)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "        \n",
    "        #入力と重みをかけてバイアスを足す\n",
    "        #(N * out_h * out_w, C * FH * FW)・(C * FH * FW, FN) → (N * out_h * out_w, FN)\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        #計算しやすいように入れ替える\n",
    "        # (N * out_h * out_w, FN) → (N, out_h, out_w, FN) → (N, FN, out_h, out_w)\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        #逆伝播の時に使うため保持する\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \"\"\"\n",
    "        #フィルター数、チャネル数、フィルターの高さ、フィルターの幅を重みのshapeをもとに作成\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        #計算しやすいように入れ替える\n",
    "        # (N, FN, out_h, out_w) → (N, out_h, out_w, FN) → (N * out_h * out_w, FN)\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "        \n",
    "        #出力の勾配を列方向に足し合わせる\n",
    "        self.db = np.sum(dout, axis=0)# → (FN)\n",
    "        \n",
    "        #順伝播時にim2col変換したものと出力の勾配の行列積を算出する\n",
    "        self.dW = np.dot(self.col.T, dout)# → (C * FH * FW, FN)\n",
    "        \n",
    "        #計算しやすいように入れ替える\n",
    "        # (C * FH * FW, FN) → (FN, C * FH * FW) → (FN, C, FH, FW)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "        \n",
    "        #出力の勾配とim2col変換をしたフィルターの行列積を求める\n",
    "        dcol = np.dot(dout, self.col_W.T)# → (N * out_h * out_w, C * FH * FW)\n",
    "        \n",
    "        #画像形式に戻す（col2im変換）\n",
    "        # (N * out_h * out_w, C * FH * FW) → (N, C, H, W)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "        \n",
    "        # 逆伝播して求めた勾配でパラメータを更新\n",
    "        self.update()\n",
    "        return dx\n",
    "    \n",
    "    def update(self):\n",
    "        self.W -= self.lr * self.dW\n",
    "        self.b -= self.lr * self.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】2次元畳み込み後の出力サイズ\n",
    "畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。\n",
    "\n",
    "## $$\n",
    "N_{h,out} =  \\frac{N_{h,in}+2P_{h}-F_{h}}{S_{h}} + 1\\\\\n",
    "N_{w,out} =  \\frac{N_{w,in}+2P_{w}-F_{w}}{S_{w}} + 1\n",
    "$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "\n",
    "$S$ : ストライドのサイズ\n",
    "\n",
    "\n",
    "$h$ が高さ方向、 $w$ が幅方向である"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_size(H, W, P, FH, FW, S):\n",
    "    out_h = (H + 2 * P - FH) / S + 1\n",
    "    out_w = (W + 2 * P - FW) / S + 1\n",
    "    return int(out_h), int(out_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】最大プーリング層の作成\n",
    "最大プーリング層のクラスMaxPool2Dを作成してください。プーリング層は数式で表さない方が分かりやすい部分もありますが、数式で表すとフォワードプロパゲーションは以下のようになります。\n",
    "\n",
    "## $$\n",
    "a_{i,j,k} = \\max_{(p,q)\\in P_{i,j}}x_{p,q,k}\n",
    "$$\n",
    "\n",
    "\n",
    "$P_{i,j}$ : i行j列への出力する場合の入力配列のインデックスの集合。 $S_{h}×S_{w}$ の範囲内の行（p）と列（q）\n",
    "\n",
    "\n",
    "$S_{h}, S_{w}$ : 高さ方向（h）と幅方向（w）のストライドのサイズ\n",
    "\n",
    "\n",
    "$(p,q)\\in P_{i,j}$ : $P_{i,j}$ に含まれる行（p）と列（q）のインデックス\n",
    "\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、kチャンネルの値\n",
    "\n",
    "\n",
    "$x_{p,q,k}$ : 入力の配列のp行q列、kチャンネルの値\n",
    "\n",
    "\n",
    "ある範囲の中でチャンネル方向の軸は残したまま最大値を計算することになります。\n",
    "\n",
    "\n",
    "バックプロパゲーションのためには、フォワードプロパゲーションのときの最大値のインデックス $(p,q)$ を保持しておく必要があります。フォワード時に最大値を持っていた箇所にそのままの誤差を流し、そこ以外には0を入れるためです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        \"\"\"Poolingレイヤー\n",
    "        --------------------------------------------------------\n",
    "            pool_h  プーリング領域の高さ\n",
    "            pool_w : プーリング領域の幅\n",
    "            stride : ストライド、デフォルトは1\n",
    "            pad : パディング、デフォルトは0\n",
    "        \"\"\"\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "        self.x = None           # 逆伝播で必要になる、順伝播時の入力\n",
    "        self.arg_max = None     # 逆伝播で必要になる、順伝播時に採用したcol_x各行の位置\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"順伝播\n",
    "        --------------------------\n",
    "            x (numpy.ndarray): 入力、形状は(N, C, H, W)\n",
    "            \n",
    "            out(numpy.ndarray): 出力、形状は(N, C, out_h, out_w)\n",
    "        \"\"\"\n",
    "        N, C, H, W = x.shape  # N:データ数、C:チャンネル数、H:高さ、W:幅\n",
    "        \n",
    "        #出力サイズを計算\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 入力データを展開、整形\n",
    "        # (N, C, H, W) → (N * out_h * out_w, C * pool_h * pool_w)\n",
    "        col_x = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        # (N * out_h * out_w, C * pool_h * pool_w) → (N * out_h * out_w * C, pool_h * pool_w)\n",
    "        col_x = col_x.reshape(-1, self.pool_h * self.pool_w)\n",
    "\n",
    "        # 出力を算出\n",
    "        # (N * out_h * out_w * C, pool_h * pool_w) → (N * out_h * out_w * C)\n",
    "        out = np.max(col_x, axis=1)\n",
    "\n",
    "        # 結果の整形\n",
    "        # (N * out_h * out_w * C) → (N, out_h, out_w, C) → (N, C, out_h, out_w)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        # 逆伝播のために保存\n",
    "        self.x = x\n",
    "        self.arg_max = np.argmax(col_x, axis=1)  # col_x各行の最大値の位置（インデックス）\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"逆伝播\n",
    "        -------------------------------\n",
    "            dout (numpy.ndarray): 右の層から伝わってくる微分値、形状は(N, C, out_h, out_w)\n",
    "\n",
    "            dx(numpy.ndarray): 微分値（勾配）、形状は(N, C, H, W)\n",
    "        \"\"\"\n",
    "        # 右の層からの微分値を整形\n",
    "        # (N, C, out_h, out_w) → (N, out_h, out_w, C)\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "\n",
    "        # 結果の微分値用のcolを0で初期化\n",
    "        # (N * out_h * out_w * C, pool_h * pool_w)\n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        \n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        \n",
    "         # 結果の微分値の整形\n",
    "        # (N * out_h * out_w * C, pool_h * pool_w) → (N, out_h, out_w, C, pool_h * pool_w)\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        # 結果の微分値の整形\n",
    "        # (N, out_h, out_w, C, pool_h * pool_w) → (N * out_h * out_w, C * pool_h * pool_w)\n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        \n",
    "        # 結果の微分値の整形\n",
    "        # (N * out_h * out_w, C * pool_h * pool_w) → (N, C, H, W)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】平滑化\n",
    "平滑化するためのFlattenクラスを作成してください。\n",
    "\n",
    "\n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。\n",
    "\n",
    "\n",
    "この平滑化のクラスを挟むことで出力前の全結合層に適した配列を作ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    \"\"\"\n",
    "    平滑化\n",
    "    -----------------------\n",
    "    forward時はチャンネル、高さ、幅の3次元を1次元に\n",
    "    backward時は元の入力の形状に\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        #入力サイズ、チャネル数、入力の高さ、幅を入力の形状に\n",
    "        N, C, H, W = x.shape\n",
    "        #平滑化\n",
    "        flatten = x.reshape(N, -1)\n",
    "        #逆伝播で入力と同じ形状にするため入力を保持\n",
    "        self.x = x\n",
    "        \n",
    "        return flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】学習と推定\n",
    "作成したConv2dを使用してMNISTを学習・推定し、Accuracyを計算してください。\n",
    "\n",
    "\n",
    "精度は低くともまずは動くことを目指してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ミニバッチを取得するクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全結合層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        \n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        \n",
    "        #初期化手法\n",
    "        self.initializer = initializer\n",
    "        \n",
    "        #最適化手法\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # 指定したinitializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = self.initializer.W(self.n_nodes1,self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        #フォワード時の入力Xをインスタンス変数として保持\n",
    "        self.X = X\n",
    "        \n",
    "        #順伝播\n",
    "        self.A = self.X@self.W + self.B\n",
    "        \n",
    "        return self.A\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        # 逆伝播\n",
    "        self.dB = np.sum(dA,axis=0)#dA・・・逆伝播する際に活性化関数に通して出力された値\n",
    "        self.dW = self.X.T@dA\n",
    "        self.dZ = dA@self.W.T\n",
    "        \n",
    "        #インスタンスの重みとバイアス自身を指定した最適手法により求めた値で更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return self.dZ\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期化手法\n",
    "### ガウス分布によるシンプルな初期化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :　重みの初期値\n",
    "        \"\"\"\n",
    "        W = self.sigma*np.random.randn(n_nodes1,n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :バイアスの初期値\n",
    "        \"\"\"\n",
    "        B = self.sigma*np.random.randn(1,n_nodes2)\n",
    "        return B\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化手法\n",
    "### 最適化手法（SGD）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "       \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        #パラメータを誤差逆伝播で算出したものに学習率をかけて更新\n",
    "        layer.W -= self.lr*layer.dW/20#バッチサイズで割る\n",
    "        layer.B -= self.lr*layer.dB/20\n",
    "        \n",
    "        #パラメータを更新したインスタンスを返す\n",
    "        return layer\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 活性化関数\n",
    "### ハイパボリックタンジェント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    '''\n",
    "    ハイパボリックタンジェント関数\n",
    "    '''\n",
    "    def forward(self, A):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.A = A\n",
    "        Z = np.tanh(self.A)\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        dA = dZ * (1 - np.tanh(self.A)**2)\n",
    "        return dA\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ソフトマックス関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n",
    "class Softmax:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        A : 各層に入力される値(batch_size, n_nodes_1)\n",
    "        dZ : バックワード時に前に流す勾配(batch_size, n_nodes1)\n",
    "\n",
    "       Returns\n",
    "        -------\n",
    "        Z : 各層からの出力される値(batch_size, n_nodes1)\n",
    "        dA : バックワード時に後ろから流れてきた勾配(batch_size, n_nodes2)\n",
    "        \"\"\"\n",
    "        def forward(self,A):\n",
    "            Z = np.exp(A)/np.sum(np.exp(A),axis=1).reshape(-1,1)\n",
    "            \n",
    "            return Z\n",
    "         \n",
    "        def backward(self,A,y):\n",
    "            dA = self.forward(A) - y\n",
    "            #back時は交差エントロピー誤差も計算\n",
    "            L = - np.sum(y * np.log(self.forward(A))) / len(y)\n",
    "            \n",
    "            return dA,L        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2次元のCNNクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d_NN():\n",
    "    \"\"\"\n",
    "    2次元の畳み込み層を加えたニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self,FN=30,FH=3,FW=3,stride=1,pad=0, epoch=10,batch_size=20,sigma=0.1,lr=0.01,verbose=False):\n",
    "        \n",
    "        #パラメータ\n",
    "        self.epoch = epoch \n",
    "        self.batch_size =  batch_size\n",
    "        self.sigma = sigma \n",
    "        self.lr = lr \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        #全結合層で使用\n",
    "        self.optimizer = SGD\n",
    "        self.initializer = SimpleInitializer\n",
    "        self.activater = Tanh()\n",
    "        self.softmax = Softmax()\n",
    "        self.flatten = Flatten()\n",
    "        \n",
    "        #畳み込み層で使用\n",
    "        self.FN = FN#フィルターの数\n",
    "        self.C = 1#チャネル数\n",
    "        self.FH = FH#フィルターの縦の大きさ\n",
    "        self.FW = FW#フィルターの幅\n",
    "        self.pad = pad#padding\n",
    "        self.stride = stride#ストライド \n",
    "        self.n_output = 10 #出力数\n",
    "        \n",
    "        #pooling層クラス呼び出しのためにプーリング フィルターのサイズを指定\n",
    "        self.pool_h = 1 # プーリングフィルターの高さ\n",
    "        self.pool_w = 1 # プーリングフィルターの幅\n",
    "        #pooling層クラスを呼び出し\n",
    "        self.max_pool = MaxPool2D(self.pool_h, self.pool_w)\n",
    "        \n",
    "        # 畳み込み層クラス呼び出しのために、重みとバイアスの初期値を生成\n",
    "        self.w = self.sigma * np.random.randn(self.FN, self.C, self.FH, self.FW)\n",
    "        self.b = self.sigma * np.random.randn(self.FN,)\n",
    "        #畳み込みクラスを呼び出し\n",
    "        self.conv = Conv2d(self.w,self.b)\n",
    "\n",
    "        # 全結合層クラスを呼び出すために、全結合層への入力を計算する\n",
    "        #畳み込み層からプーリング 層\n",
    "        out_h, out_w = self.out_size(28,28, self.pad, self.FH, self.FW, self.stride)\n",
    "        \n",
    "        #プーリング 層から全結合層\n",
    "        out_h, out_w = self.out_size(out_h, out_w, 0, self.pool_h, self.pool_w, self.pool_h)\n",
    "        \n",
    "        #全結合層への入力を計算\n",
    "        node_n = self.FN * out_h * out_w\n",
    "        \n",
    "        #全結合層クラスを呼び出し\n",
    "        self.FC = FC(node_n, self.n_output, self.initializer(self.sigma), self.optimizer(self.lr))\n",
    "        \n",
    "        #グラフ描画用にlossを保存するリスト\n",
    "        self.loss_train = []\n",
    "        self.loss_val = []\n",
    "\n",
    "    #畳み込み層からの出力サイズを計算    \n",
    "    def out_size(self,H, W, P, FH, FW, S):\n",
    "        out_h = (H + 2 * P - FH) / S + 1\n",
    "        out_w = (W + 2 * P - FW) / S + 1\n",
    "        return int(out_h), int(out_w)#float➡︎int\n",
    "\n",
    "    #学習\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"  \n",
    "        #バッチごとに計算\n",
    "        for epoch in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=epoch)\n",
    "            #エポックごとにlossを初期化\n",
    "            loss = 0\n",
    "            val_loss = 0\n",
    "            #エポックごとにイテレーション数を初期化\n",
    "            iter_num = 0\n",
    "            \n",
    "            for mini_X, mini_y in get_mini_batch:\n",
    "                # フォワード\n",
    "                A1 = self.conv.forward(mini_X)\n",
    "                Z1 = self.activater.forward(A1)\n",
    "                P1 = self.max_pool.forward(Z1)\n",
    "                F1 = self.flatten.forward(P1)\n",
    "                A2 = self.FC.forward(F1)\n",
    "                Z2 = self.softmax.forward(A2)\n",
    "\n",
    "                # バックワード\n",
    "                dA2, loss = self.softmax.backward(Z2, mini_y)\n",
    "                dZ2 = self.FC.backward(dA2)\n",
    "                dF1 = self.flatten.backward(dZ2)\n",
    "                dP1 = self.max_pool.forward(dF1)\n",
    "                dA1 = self.activater.backward(dP1)\n",
    "                dZ1 = self.conv.backward(dA1)\n",
    "            \n",
    "                # 求めたパラメータで再度通る\n",
    "                A1 = self.conv.forward(X)\n",
    "                Z1 = self.activater.forward(A1)\n",
    "                P1 = self.max_pool.forward(Z1)\n",
    "                F1 = self.flatten.forward(P1)\n",
    "                A2 = self.FC.forward(F1)\n",
    "                Z2 = self.softmax.forward(A2)\n",
    "                \n",
    "                 # iイテレーションごとに交差エントロピーを計算\n",
    "                loss += self.softmax.backward(Z2, y)[1]\n",
    "                \n",
    "                #エポックの平均を出すためにイテレーション数を記録\n",
    "                iter_num+=1\n",
    "                \n",
    "                #valデータが入力されたら順伝播＆softmax.backwardで交差エントロピー誤差を算出\n",
    "                if X_val is not None:\n",
    "                    A1 = self.conv.forward(X_val)\n",
    "                    Z1 = self.activater.forward(A1)\n",
    "                    P1 = self.max_pool.forward(Z1)\n",
    "                    F1 = self.flatten.forward(P1)\n",
    "                    A2 = self.FC.forward(F1)\n",
    "                    Z2 = self.softmax.forward(A2)         \n",
    "                    val_loss += self.softmax.backward(Z2, y_val)[1]\n",
    "                    \n",
    "            #エポックごとのlossの平均を算出、リストに格納\n",
    "            ave_loss = loss/iter_num\n",
    "            ave_val_loss = val_loss/iter_num\n",
    "            self.loss_train.append(ave_loss)\n",
    "            self.loss_val.append(ave_val_loss)\n",
    "            \n",
    "            if self.verbose:\n",
    "                #verboseをTrueにした際は各エポックごとの損失の平均を出力する\n",
    "                print(\"Epoch{}\".format(epoch))\n",
    "                print(\"loss:{:.10f}/val_loss:{:.10f}\".format(ave_loss,ave_val_loss))\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        #学習したパラメータで畳み込み層から全部通る\n",
    "        A1 = self.conv.forward(X)\n",
    "        Z1 = self.activater.forward(A1)\n",
    "        P1 = self.max_pool.forward(Z1)\n",
    "        F1 = self.flatten.forward(P1)\n",
    "        A2 = self.FC.forward(F1)\n",
    "        Z2 = self.softmax.forward(A2)\n",
    "        #sofmaxを通した最後の層で確率が一番高いものを推定結果とする\n",
    "        return np.argmax(Z2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット読み込み\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# # チャネル数の軸を追加\n",
    "X_train = X_train[:,None]\n",
    "X_test = X_test[:,None]\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "\n",
    "# ワンホットエンコーディング\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_val[:, np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0\n",
      "loss:0.8235570143/val_loss:2.2116118726\n",
      "Epoch1\n",
      "loss:0.7866961751/val_loss:1.9787450265\n",
      "Epoch2\n",
      "loss:0.7008518148/val_loss:1.8989777366\n",
      "Epoch3\n",
      "loss:0.6871410808/val_loss:1.8610385125\n",
      "Epoch4\n",
      "loss:0.6573725843/val_loss:1.8428555425\n",
      "Epoch5\n",
      "loss:0.6699137162/val_loss:1.8478033122\n",
      "Epoch6\n",
      "loss:0.6890916606/val_loss:1.8276997300\n",
      "Epoch7\n",
      "loss:0.6798342042/val_loss:1.8381619397\n",
      "Epoch8\n",
      "loss:0.6539848767/val_loss:1.8225934345\n",
      "Epoch9\n",
      "loss:0.6934500247/val_loss:1.8198000870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6235833333333334"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C2NN =  Conv2d_NN(\n",
    "    FN=20,\n",
    "    FH=5,\n",
    "    FW=5,\n",
    "    stride=1,\n",
    "    pad=0, \n",
    "    epoch=10,\n",
    "    batch_size=20,\n",
    "    sigma=0.1,\n",
    "    lr=0.01,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "C2NN.fit(X_train[:100], y_train_one_hot[:100], X_val[:50], y_test_one_hot[:50])\n",
    "pred = C2NN.predict(X_val)\n",
    "accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14f81e390>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(C2NN.loss_train, label='train')\n",
    "plt.plot(C2NN.loss_val, label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題9】出力サイズとパラメータ数の計算\n",
    "CNNモデルを構築する際には、全結合層に入力する段階で特徴量がいくつになっているかを事前に計算する必要があります。\n",
    "\n",
    "\n",
    "また、巨大なモデルを扱うようになると、メモリや計算速度の関係でパラメータ数の計算は必須になってきます。フレームワークでは各層のパラメータ数を表示させることが可能ですが、意味を理解していなくては適切な調整が行えません。\n",
    "\n",
    "\n",
    "以下の3つの畳み込み層の出力サイズとパラメータ数を計算してください。パラメータ数についてはバイアス項も考えてください。\n",
    "\n",
    "\n",
    "1.\n",
    "\n",
    "\n",
    "入力サイズ : 144×144, 3チャンネル\n",
    "フィルタサイズ : 3×3, 6チャンネル\n",
    "ストライド : 1\n",
    "パディング : なし\n",
    "\n",
    "2.\n",
    "\n",
    "\n",
    "入力サイズ : 60×60, 24チャンネル\n",
    "フィルタサイズ : 3×3, 48チャンネル\n",
    "ストライド　: 1\n",
    "パディング : なし\n",
    "\n",
    "3.\n",
    "\n",
    "\n",
    "入力サイズ : 20×20, 10チャンネル\n",
    "フィルタサイズ: 3×3, 20チャンネル\n",
    "ストライド : 2\n",
    "パディング : なし\n",
    "\n",
    "＊最後の例は丁度良く畳み込みをすることができない場合です。フレームワークでは余ったピクセルを見ないという処理が行われることがあるので、その場合を考えて計算してください。端が欠けてしまうので、こういった設定は好ましくないという例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_size(H, W, P, FH, FW, S):\n",
    "    \"\"\"\n",
    "    出力のサイズを計算する関数\n",
    "    \"\"\"\n",
    "    out_h = (H + 2 * P - FH) / S + 1\n",
    "    out_w = (W + 2 * P - FW) / S + 1\n",
    "    \n",
    "    return int(out_h), int(out_w)\n",
    "\n",
    "\n",
    "def cul_param(in_C,FW,FH,f_C):\n",
    "    \"\"\"\n",
    "    パラメータの数を計算する関数\n",
    "    入力サイズのチャンネル数×フィルターの横×フィルターの縦×フィルターサイズチャンネル数+フィルターサイズチャンネル数\n",
    "    \"\"\"\n",
    "    return in_C*FW*FH*f_C+f_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力サイズ：(142, 142)\n",
      "パラメータ数：168\n"
     ]
    }
   ],
   "source": [
    "# 1.入力サイズ : 144×144, 3チャンネル フィルタサイズ : 3×3, 6チャンネル ストライド : 1 パディング : なし\n",
    "\n",
    "print(\"出力サイズ：{}\".format(out_size(144,144,0,3,3,1)))\n",
    "print(\"パラメータ数：{}\".format(cul_param(3,3,3,6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力サイズ：(58, 58)\n",
      "パラメータ数：10416\n"
     ]
    }
   ],
   "source": [
    "#2入力サイズ : 60×60, 24チャンネル フィルタサイズ : 3×3, 48チャンネル ストライド　: 1 パディング : なし\n",
    "\n",
    "print(\"出力サイズ：{}\".format(out_size(60, 60, 0, 3, 3, 1)))\n",
    "print(\"パラメータ数：{}\".format(cul_param(3, 3, 24, 48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力サイズ：(9, 9)\n",
      "パラメータ数：1820\n"
     ]
    }
   ],
   "source": [
    "#3.入力サイズ : 20×20, 10チャンネル フィルタサイズ: 3×3, 20チャンネル ストライド : 2 パディング : なし\n",
    "\n",
    "print(\"出力サイズ：{}\".format(out_size(20, 20, 0, 3, 3, 2)))\n",
    "print(\"パラメータ数：{}\".format(cul_param(3, 3, 10, 20)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
